name: Analyze Spark repository to extract build dependency and test list

on:
  workflow_dispatch:
  schedule:
   - cron: '0 0 * * 0'
jobs:
  analyze-spark-package:
    runs-on: ubuntu-latest
    env:
      python: 3.7
      java: 1.8
    strategy:
      fail-fast: true
    steps:
      - name: Checkout predictive-testing repository
        uses: actions/checkout@v2
        # In order to fetch changed files
        with:
          fetch-depth: 0
      - name: Checkout Spark repository
        uses: actions/checkout@v2
        with:
          fetch-depth: 0
          repository: apache/spark
          ref: master
          path: spark-master
      - name: Generate output name by using Spark HEAD commit sha
        run: |
          OUTPUT_NAME=`git -C ./spark-master rev-parse --abbrev-ref HEAD`-`git -C  ./spark-master rev-parse --short HEAD`-`date '+%Y%m%d%H%M'`
          echo "OUTPUT_NAME=${OUTPUT_NAME}" >> $GITHUB_ENV
      - name: Install Python ${{ env.python }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ env.python }}
          architecture: x64
      - name: Install Python packages (Python ${{ env.python }})
        run: python -m pip install -r ./bin/requirements.txt
      - name: Install JDK ${{ env.java }}
        uses: actions/setup-java@v1
        with:
          java-version: ${{ env.java }}
      - name: Build with Maven
        run: |
          export MAVEN_OPTS="-Xss64m -Xmx2g -XX:ReservedCodeCacheSize=1g -Dorg.slf4j.simpleLogger.defaultLogLevel=WARN"
          export MAVEN_CLI_OPTS="--no-transfer-progress"
          export JAVA_VERSION=${{ env.java }}
          cd spark-master && ./build/mvn $MAVEN_CLI_OPTS -DskipTests -Pyarn -Pmesos -Pkubernetes -Phive -Phive-thriftserver -Phadoop-cloud -Pdocker-integration-tests -Djava.version=$JAVA_VERSION test-compile
      - name: Analyze Spark class dependencies
        run: ./bin/analyze-spark-package.sh ./spark-master "${{ env.OUTPUT_NAME }}"
      - name: Update `models/spark/indexes/latest`
        if: success()
        run: |
          cd models/spark/indexes
          rm latest
          ln -s ${{ env.OUTPUT_NAME }} latest
      - name: Create Pull Request
        if: success()
        uses: peter-evans/create-pull-request@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: Adds latest snapshot in `models/spark/indexes/${{ env.OUTPUT_NAME }}`
          committer: GitHub <noreply@github.com>
          author: ${{ github.actor }} <${{ github.actor }}@users.noreply.github.com>
          signoff: false
          branch: analyze-spark-package-${{ github.job }}-${{ github.run_id }}
          delete-branch: true
          title: Adds latest snapshot in `models/spark/indexes/${{ env.OUTPUT_NAME }}`
          body: |
            Automated changes by the `${{ github.job }}` workflow (run_id=${{ github.run_id }}).
      - name: Upload output as artifact
        if: success()
        uses: actions/upload-artifact@v2
        with:
          name: spark-index-${{env.OUTPUT_NAME}}
          path: ${{ env.OUTPUT_NAME }}
