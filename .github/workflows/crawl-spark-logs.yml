name: Crawl Spark GitHub logs

on:
  workflow_dispatch:
    inputs:
      sinceDate:
        description: 'Since date'
        default: '1 month ago'
        required: true
  schedule:
   - cron: '0 0 */7 * *'
jobs:
  crawl-spark-logs:
    runs-on: ubuntu-latest
    env:
      python: 3.7
    strategy:
      fail-fast: false
    steps:
      - name: Checkout predictive-testing repository
        uses: actions/checkout@v2
        # In order to fetch changed files
        with:
          fetch-depth: 0
      - name: Install Python ${{ env.python }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ env.python }}
          architecture: x64
      - name: Install Python packages (Python ${{ env.python }})
        run: python -m pip install -r ./bin/requirements.txt
      - name: Get latest workflow run status
        uses: actions/github-script@v4
        id: latest-workflow-status
        if: ${{ github.event_name == 'schedule' }}
        with:
          result-encoding: string
          script: |
            const runs = await github.actions.listWorkflowRuns({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'crawl-spark-logs.yml',
              per_page: 2
            })
            if (runs.data.workflow_runs.length == 2) {
              return '' + runs.data.workflow_runs[1].id
            } else {
              return ''
            }
      - name: Get latest artifact archive url
        uses: actions/github-script@v4
        id: latest-artifact-archive-url
        if: ${{ steps.latest-workflow-status.outputs.result != '' }}
        with:
          result-encoding: string
          script: |
            const artifacts = await github.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: ${{ steps.latest-workflow-status.outputs.result }},
              per_page: 1
            })
            if (artifacts.data.artifacts.length != 0) {
              return artifacts.data.artifacts[0].archive_download_url
            } else {
              return ''
            }
      - name: Fetch latest artifact
        if: ${{ steps.latest-artifact-archive-url.outputs.result != '' }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          curl -L -H "Authorization: token $GITHUB_TOKEN" "${{ steps.latest-artifact-archive-url.outputs.result }}" -o output.zip
          unzip -q output.zip -d latest_output
      - name: Check if latest output exists
        uses: andstor/file-existence-action@v1
        id: check-if-latest-output-exists
        with:
          files: "latest_output/.run-meta.json"
      - name: Check if resume file exists
        uses: andstor/file-existence-action@v1
        id: check-if-resume-file-exists
        with:
          files: "latest_output/.resume-meta.lst"
      - name: Use `sinceDate` for `--since` option
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run: |
          echo "${{ github.event_name }}"
          SINCE_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ" -d '${{ github.event.inputs.sinceDate }}'`
          echo "SINCE_DATE=${SINCE_DATE}" >> $GITHUB_ENV
      - name: Set a default value for `--since` option
        if: ${{ github.event_name == 'schedule' &&
          steps.check-if-latest-output-exists.outputs.files_exists == 'false' &&
          steps.check-if-resume-file-exists.outputs.files_exists == 'false' }}
        run: |
          SINCE_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ" -d '7 days ago'`
          echo "SINCE_DATE=${SINCE_DATE}" >> $GITHUB_ENV
      - name: Compute `--since` option value form the latest run datetime
        if: ${{ github.event_name == 'schedule' &&
          steps.check-if-latest-output-exists.outputs.files_exists == 'true' &&
          steps.check-if-resume-file-exists.outputs.files_exists == 'false' }}
        run: |
          SINCE_DATE=`cat latest_output/.run-meta.json | jq --raw-output .until`
          echo "SINCE_DATE=${SINCE_DATE}" >> $GITHUB_ENV
      - name: Run script to collect GitHub logs
        if: ${{ steps.check-if-resume-file-exists.outputs.files_exists == 'false' }}
        env:
          GITHUB_TOKEN: ${{ secrets.LOG_CRAWLER_API_KEY }}
        run: |
          ./bin/crawl-spark-github-logs.sh --output output --overwrite --since "${{ env.SINCE_DATE }}"
      - name: Resume last run to collect GitHub logs
        if: ${{ steps.check-if-resume-file-exists.outputs.files_exists == 'true' }}
        env:
          GITHUB_TOKEN: ${{ secrets.LOG_CRAWLER_API_KEY }}
        run: |
          mv latest_output output
          ./bin/crawl-spark-github-logs.sh --output output --resume
      - name: Appends the collected logs into `models/spark/logs/github-logs.json`
        if: success()
        run: cat output/github-logs.json >> models/spark/logs/github-logs.json
      - name: Create Pull Request
        if: success()
        uses: peter-evans/create-pull-request@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: Appends the collected logs (since='${{ env.SINCE_DATE }}') into `models/spark/logs/github-logs.json`
          committer: GitHub <noreply@github.com>
          author: ${{ github.actor }} <${{ github.actor }}@users.noreply.github.com>
          signoff: false
          branch: crawl-spark-logs-${{ github.job }}-${{ github.run_id }}
          delete-branch: true
          title: Appends the collected logs (since='${{ env.SINCE_DATE }}') into `models/spark/logs/github-logs.json`
          body: |
            Automated changes by the `${{ github.job }}` workflow (run_id=${{ github.run_id }}).
      - name: Upload output as artifact
        if: always()
        uses: actions/upload-artifact@v2
        with:
          name: spark-github-logs
          path: output/*
